# Abliterate Apertus 70B Instruct — norm-preserving biprojected abliteration
# Model: swiss-ai/Apertus-70B-Instruct-2509 (141 GB BF16 safetensors)
# Tool: github.com/jim-plus/llm-abliteration --normpreserve --projected
#
# Needs: 80GB+ VRAM (4-bit quant) or 140GB+ (BF16 native)
# Disk: ~350GB (model + abliterated copy + working space)
#
# Expected runtime: 2-4 hours ($0.30-1.50 depending on GPU)

requirements:
  min_disk_gb: 350             # 141GB model + 141GB output + pip + working space
  min_ram_gb: 128              # Shard-at-a-time needs ~5GB per shard in CPU RAM
  min_vram_gb: 80              # 70B with 4-bit quant ~40GB, BF16 ~140GB
  min_vram_per_gpu_gb: 0       # Multi-GPU OK if total is enough
  min_gpu_flops_tflops: null
  min_bandwidth_mbps: 100      # Reasonable download speed
  max_price_per_hour: 0.60     # Budget cap

instance:
  disk_gb: 350
  image: "pytorch/pytorch:2.5.1-cuda12.4-cudnn9-devel"
  type: "interruptible"        # Cheap interruptible is fine

countries:
  blacklist: [ "CN", "RU", "BY", "VN" ]
  allowlist: []

monitoring:
  disk_usage_threshold_percent: 80
  check_interval_seconds: 60

ssh:
  forwards:
    - local_port: 2222
      remote_port: 22
      remote_host: localhost
      local_bind: "127.0.0.1"

logging:
  file: abliterate-apertus.log

autorent:
  search_interval_seconds: 300
  verify_timeout_seconds: 600
  max_attempts_per_cycle: 5
  auto_shutdown: true
  destroy_on_exit: false       # Don't destroy on Ctrl+C — we need to verify transfer
  connect: true
  startup_script: abliterate-apertus-setup.sh
  startup_files: [setup-lib.sh, vast-transfer-key, abliterate-apertus-job.sh]
  bid_margin_percent: 5
  bid_margin_dollars: 0.0
