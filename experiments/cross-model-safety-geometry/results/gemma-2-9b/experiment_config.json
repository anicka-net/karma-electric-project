{
  "model_id": "google/gemma-2-9b-it",
  "model_type": "Gemma2ForCausalLM",
  "n_layers": 42,
  "capping_layers": [
    29,
    30,
    31,
    32,
    33,
    34,
    35,
    36,
    37
  ],
  "analysis_layers": [
    29,
    30,
    31,
    32,
    33,
    34,
    35,
    36,
    37,
    38,
    39,
    40,
    41
  ],
  "test": "all",
  "seed": 42,
  "timestamp": "2026-02-28T13:52:59.315806"
}