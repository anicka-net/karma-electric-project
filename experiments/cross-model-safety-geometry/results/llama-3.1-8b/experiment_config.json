{
  "model_id": "meta-llama/Llama-3.1-8B-Instruct",
  "model_type": "LlamaForCausalLM",
  "n_layers": 32,
  "capping_layers": [
    22,
    23,
    24,
    25,
    26,
    27,
    28
  ],
  "analysis_layers": [
    22,
    23,
    24,
    25,
    26,
    27,
    28,
    29,
    30,
    31
  ],
  "test": "censorship",
  "seed": 42,
  "timestamp": "2026-02-27T10:56:56.280233"
}